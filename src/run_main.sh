#!/bin/bash
#SBATCH -N 1 # number of nodes
#SBATCH -p cox
#SBATCH -n 8 # number of cores
#SBATCH --mem 10000 # memory pool for all cores
#SBATCH --gres=gpu:1 # memory pool for all cores
#SBATCH -t 1-00:00 # time (D-HH:MM)

#SBATCH -o _train_%j.%N.out # STDOUT
#SBATCH -e _train_%j.%N.err # STDERR

module load python/3.6.3-fasrc01
module load cuda/9.2.88-fasrc01
source activate deep-svdd
module load GCCcore/6.4.0
nvidia-smi -L

# Run
#python main.py cycif cycif_Net ../log/cycif-run1 /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --objective one-class --lr 0.0001 --n_epochs 300 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain True --ae_lr 0.0001 --ae_n_epochs 150 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 0.5e-3;
#python main.py cycif cycif_Net ../log/cycif-run2 /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --objective one-class --lr 0.0001 --n_epochs 300 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-3 --pretrain True --ae_lr 0.0001 --ae_n_epochs 100 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 0.5e-3;
#python main.py cycif cycif_Net ../log/cycif-run3 /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --objective one-class --lr 0.001 --n_epochs 200 --lr_milestone 50 --batch_size 16 --weight_decay 5e-3 --pretrain True --ae_lr 0.001 --ae_n_epochs 100 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 5e-3;
#python main.py cycif cycif_Net ../log/cycif-run4-no-bias-terms /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --objective one-class --lr 0.0001 --n_epochs 300 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain True --ae_lr 0.0001 --ae_n_epochs 150 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 0.5e-3;
#python main.py cycif cycif_Net ../log/cycif-run5-no-pre-training /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --objective one-class --lr 0.0001 --n_epochs 300 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False
#python main.py cycif cycif_Net ../log/cycif-run6-multi-center /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --objective one-class --lr 0.0001 --n_epochs 300 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False
#python main.py cycif cycif_Net ../log/cycif-run7-multi-center-k-2-update-with-pretrain /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --objective one-class --lr 0.0001 --n_epochs 300 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain True --ae_lr 0.0001 --ae_n_epochs 150 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 0.5e-3;
#python main.py cycif cycif_Net ../log/cycif-run8-multi-center-k-4-update-with-pretrain /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --objective one-class --lr 0.0001 --n_epochs 300 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain True --ae_lr 0.0001 --ae_n_epochs 150 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 0.5e-3;
#python main.py cycif cycif_Net ../log/cycif-run9-partial-fit-multi-center-k-4-update-with-pretrain /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --objective one-class --lr 0.0001 --n_epochs 300 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain True --ae_lr 0.0001 --ae_n_epochs 150 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 0.5e-3;
#python main.py cycif cycif_Net ../log/cycif-run10-multi-center-k-4-full-kmeans /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/cycif-run4-no-bias-terms/model.tar --objective one-class --lr 0.0001 --n_epochs 300 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False;
#python main.py cycif cycif_Net ../log/cycif-run11-multi-center-k-2-full-kmeans /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/cycif-run4-no-bias-terms/model.tar --objective one-class --lr 0.0001 --n_epochs 300 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False;

### ADD --number_clusters!!! ###
#python main.py cycif cycif_Net ../log/cycif-run12-multi-center-k-6-full-kmeans /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/cycif-run4-no-bias-terms/model.tar --number_clusters 6 --objective one-class --lr 0.0001 --n_epochs 300 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False;
#python main.py cycif cycif_Net ../log/cycif-run13-multi-center-k-8-full-kmeans /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/cycif-run4-no-bias-terms/model.tar --number_clusters 8 --objective one-class --lr 0.0001 --n_epochs 300 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False;

### KMeans Experiments ###
#python main.py cycif cycif_Net ../log/end-to-end-kmeans-models/multi-center-naive /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --number_clusters 1 --objective one-class --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain True --ae_lr 0.0001 --ae_n_epochs 100 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 5e-3;
#python main.py cycif cycif_Net ../log/end-to-end-kmeans-models/multi-center-k-2 /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/end-to-end-kmeans-models/multi-center-naive/model.tar --number_clusters 2 --objective one-class --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False --ae_lr 0.0001 --ae_n_epochs 100 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 5e-3;
#python main.py cycif cycif_Net ../log/end-to-end-kmeans-models/multi-center-k-3 /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/end-to-end-kmeans-models/multi-center-naive/model.tar --number_clusters 3 --objective one-class --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False --ae_lr 0.0001 --ae_n_epochs 100 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 5e-3;
#python main.py cycif cycif_Net ../log/end-to-end-kmeans-models/multi-center-k-4 /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/end-to-end-kmeans-models/multi-center-naive/model.tar --number_clusters 4 --objective one-class --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False --ae_lr 0.0001 --ae_n_epochs 100 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 5e-3;
#python main.py cycif cycif_Net ../log/end-to-end-kmeans-models/multi-center-k-5 /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/end-to-end-kmeans-models/multi-center-naive/model.tar --number_clusters 5 --objective one-class --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False --ae_lr 0.0001 --ae_n_epochs 100 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 5e-3;
#python main.py cycif cycif_Net ../log/end-to-end-kmeans-models/multi-center-k-6 /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/end-to-end-kmeans-models/multi-center-naive/model.tar --number_clusters 6 --objective one-class --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False --ae_lr 0.0001 --ae_n_epochs 100 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 5e-3;

### KMeans Experiments No Scaling of Latent Space and Early Stopping ###
#python main.py cycif cycif_Net ../log/end-to-end-kmeans-models-no-scaling/multi-center-naive-no-validation-data /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --number_clusters 1 --objective one-class --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain True --ae_lr 0.0001 --ae_n_epochs 100 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 5e-3;
#python main.py cycif cycif_Net ../log/end-to-end-kmeans-models-no-scaling/multi-center-naive /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --number_clusters 1 --objective one-class --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain True --ae_lr 0.0001 --ae_n_epochs 100 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 5e-3;
#python main.py cycif cycif_Net ../log/end-to-end-kmeans-models-no-scaling/multi-center-k-2 /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/end-to-end-kmeans-models-no-scaling/multi-center-naive/model.tar --number_clusters 2 --objective one-class --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False --ae_lr 0.0001 --ae_n_epochs 100 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 5e-3;
#python main.py cycif cycif_Net ../log/end-to-end-kmeans-models-no-scaling/multi-center-k-4 /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/end-to-end-kmeans-models-no-scaling/multi-center-naive/model.tar --number_clusters 4 --objective one-class --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False --ae_lr 0.0001 --ae_n_epochs 100 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 5e-3;
#python main.py cycif cycif_Net ../log/end-to-end-kmeans-models-no-scaling/multi-center-k-6 /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/end-to-end-kmeans-models-no-scaling/multi-center-naive/model.tar --number_clusters 6 --objective one-class --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False --ae_lr 0.0001 --ae_n_epochs 100 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 5e-3;
#python main.py cycif cycif_Net ../log/end-to-end-kmeans-models-no-scaling/multi-center-k-8 /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/end-to-end-kmeans-models-no-scaling/multi-center-naive/model.tar --number_clusters 8 --objective one-class --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False --ae_lr 0.0001 --ae_n_epochs 100 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 5e-3;
#python main.py cycif cycif_Net ../log/end-to-end-kmeans-models-no-scaling/multi-center-k-10 /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/end-to-end-kmeans-models-no-scaling/multi-center-naive/model.tar --number_clusters 10 --objective one-class --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False --ae_lr 0.0001 --ae_n_epochs 100 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 5e-3;

### MNIST TEST ###
#python main.py mnist mnist_LeNet ../log/mnist-run-test1/k-1 /n/pfister_lab2/Lab/enovikov/shared/Data/MNIST --objective one-class --lr 0.0001 --n_epochs 75 --lr_milestone 50 --batch_size 200 --weight_decay 0.5e-6 --pretrain True --ae_lr 0.0001 --ae_n_epochs 50 --ae_lr_milestone 50 --ae_batch_size 200 --ae_weight_decay 0.5e-3 --normal_class 3 --number_clusters 1;
#python main.py mnist mnist_LeNet ../log/mnist-run-test1/k-2 /n/pfister_lab2/Lab/enovikov/shared/Data/MNIST --objective one-class --lr 0.0001 --n_epochs 75 --lr_milestone 50 --batch_size 200 --weight_decay 0.5e-6 --pretrain True --ae_lr 0.0001 --ae_n_epochs 50 --ae_lr_milestone 50 --ae_batch_size 200 --ae_weight_decay 0.5e-3 --normal_class 3 --number_clusters 2;
#python main.py mnist mnist_LeNet ../log/mnist-run-test1/k-4 /n/pfister_lab2/Lab/enovikov/shared/Data/MNIST --objective one-class --lr 0.0001 --n_epochs 75 --lr_milestone 50 --batch_size 200 --weight_decay 0.5e-6 --pretrain True --ae_lr 0.0001 --ae_n_epochs 50 --ae_lr_milestone 50 --ae_batch_size 200 --ae_weight_decay 0.5e-3 --normal_class 3 --number_clusters 4;
#python main.py mnist mnist_LeNet ../log/mnist-run-test1/k-6 /n/pfister_lab2/Lab/enovikov/shared/Data/MNIST --objective one-class --lr 0.0001 --n_epochs 75 --lr_milestone 50 --batch_size 200 --weight_decay 0.5e-6 --pretrain True --ae_lr 0.0001 --ae_n_epochs 50 --ae_lr_milestone 50 --ae_batch_size 200 --ae_weight_decay 0.5e-3 --normal_class 3 --number_clusters 6;
#python main.py mnist mnist_LeNet ../log/mnist-run-test1/New-UMAP-embedding-Deep-SVDD/k-1 /n/pfister_lab2/Lab/enovikov/shared/Data/MNIST --objective one-class --lr 0.0001 --n_epochs 75 --lr_milestone 50 --batch_size 200 --weight_decay 0.5e-6 --pretrain True --ae_lr 0.0001 --ae_n_epochs 50 --ae_lr_milestone 50 --ae_batch_size 200 --ae_weight_decay 0.5e-3 --normal_class 3 --number_clusters 1;
#python main.py mnist mnist_LeNet ../log/mnist-run-test1/New-UMAP-embedding-Deep-SVDD/k-2 /n/pfister_lab2/Lab/enovikov/shared/Data/MNIST --objective one-class --lr 0.0001 --n_epochs 75 --lr_milestone 50 --batch_size 200 --weight_decay 0.5e-6 --pretrain True --ae_lr 0.0001 --ae_n_epochs 50 --ae_lr_milestone 50 --ae_batch_size 200 --ae_weight_decay 0.5e-3 --normal_class 3 --number_clusters 2;
#python main.py mnist mnist_LeNet ../log/mnist-run-test1/New-UMAP-embedding-Deep-SVDD/k-4 /n/pfister_lab2/Lab/enovikov/shared/Data/MNIST --objective one-class --lr 0.0001 --n_epochs 75 --lr_milestone 50 --batch_size 200 --weight_decay 0.5e-6 --pretrain True --ae_lr 0.0001 --ae_n_epochs 50 --ae_lr_milestone 50 --ae_batch_size 200 --ae_weight_decay 0.5e-3 --normal_class 3 --number_clusters 4;
#python main.py mnist mnist_LeNet ../log/mnist-run-test1/New-UMAP-embedding-Deep-SVDD/k-6 /n/pfister_lab2/Lab/enovikov/shared/Data/MNIST --objective one-class --lr 0.0001 --n_epochs 75 --lr_milestone 50 --batch_size 200 --weight_decay 0.5e-6 --pretrain True --ae_lr 0.0001 --ae_n_epochs 50 --ae_lr_milestone 50 --ae_batch_size 200 --ae_weight_decay 0.5e-3 --normal_class 3 --number_clusters 6;

### MNIST TEST - New UMAP embedding for Deep SVDD trained model on test data ###
#python main.py mnist mnist_LeNet ../log/mnist-run-test1/New-UMAP-embedding-Testing-Data/k-1 /n/pfister_lab2/Lab/enovikov/shared/Data/MNIST --objective one-class --lr 0.0001 --n_epochs 75 --lr_milestone 50 --batch_size 200 --weight_decay 0.5e-6 --pretrain True --ae_lr 0.0001 --ae_n_epochs 50 --ae_lr_milestone 50 --ae_batch_size 200 --ae_weight_decay 0.5e-3 --normal_class 3 --number_clusters 1;
#python main.py mnist mnist_LeNet ../log/mnist-run-test1/New-UMAP-embedding-Testing-Data/k-4 /n/pfister_lab2/Lab/enovikov/shared/Data/MNIST --objective one-class --lr 0.0001 --n_epochs 75 --lr_milestone 50 --batch_size 200 --weight_decay 0.5e-6 --pretrain False --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/mnist-run-test1/New-UMAP-embedding-Testing-Data/k-1/model.tar --ae_lr 0.0001 --ae_n_epochs 50 --ae_lr_milestone 50 --ae_batch_size 200 --ae_weight_decay 0.5e-3 --normal_class 3 --number_clusters 4;
#python main.py mnist mnist_LeNet ../log/mnist-run-test1/New-UMAP-embedding-Testing-Data/k-2 /n/pfister_lab2/Lab/enovikov/shared/Data/MNIST --objective one-class --lr 0.0001 --n_epochs 75 --lr_milestone 50 --batch_size 200 --weight_decay 0.5e-6 --pretrain False --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/mnist-run-test1/New-UMAP-embedding-Testing-Data/k-1/model.tar --ae_lr 0.0001 --ae_n_epochs 50 --ae_lr_milestone 50 --ae_batch_size 200 --ae_weight_decay 0.5e-3 --normal_class 3 --number_clusters 2;

### MNIST TEST - No min operation for gradient ###
#python main.py mnist mnist_LeNet ../log/mnist-run-test1/No-Min-Gradient-Operation/k-1 /n/pfister_lab2/Lab/enovikov/shared/Data/MNIST --objective one-class --lr 0.0001 --n_epochs 75 --lr_milestone 50 --batch_size 200 --weight_decay 0.5e-6 --pretrain True --ae_lr 0.0001 --ae_n_epochs 50 --ae_lr_milestone 50 --ae_batch_size 200 --ae_weight_decay 0.5e-3 --normal_class 3 --number_clusters 1;
#python main.py mnist mnist_LeNet ../log/mnist-run-test1/No-Min-Gradient-Operation/k-2 /n/pfister_lab2/Lab/enovikov/shared/Data/MNIST --objective one-class --lr 0.0001 --n_epochs 75 --lr_milestone 50 --batch_size 200 --weight_decay 0.5e-6 --pretrain False --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/mnist-run-test1/No-Min-Gradient-Operation/k-1/model.tar --ae_lr 0.0001 --ae_n_epochs 50 --ae_lr_milestone 50 --ae_batch_size 200 --ae_weight_decay 0.5e-3 --normal_class 3 --number_clusters 2;
#python main.py mnist mnist_LeNet ../log/mnist-run-test1/No-Min-Gradient-Operation/k-4 /n/pfister_lab2/Lab/enovikov/shared/Data/MNIST --objective one-class --lr 0.0001 --n_epochs 75 --lr_milestone 50 --batch_size 200 --weight_decay 0.5e-6 --pretrain False --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/mnist-run-test1/No-Min-Gradient-Operation/k-1/model.tar --ae_lr 0.0001 --ae_n_epochs 50 --ae_lr_milestone 50 --ae_batch_size 200 --ae_weight_decay 0.5e-3 --normal_class 3 --number_clusters 4;
#python main.py mnist mnist_LeNet ../log/mnist-run-test1/No-Min-Gradient-Operation/k-3 /n/pfister_lab2/Lab/enovikov/shared/Data/MNIST --objective one-class --lr 0.0001 --n_epochs 75 --lr_milestone 50 --batch_size 200 --weight_decay 0.5e-6 --pretrain False --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/mnist-run-test1/No-Min-Gradient-Operation/k-1/model.tar --ae_lr 0.0001 --ae_n_epochs 50 --ae_lr_milestone 50 --ae_batch_size 200 --ae_weight_decay 0.5e-3 --normal_class 3 --number_clusters 3;
#python main.py mnist mnist_LeNet ../log/mnist-run-test1/No-Min-Gradient-Operation/k-6 /n/pfister_lab2/Lab/enovikov/shared/Data/MNIST --objective one-class --lr 0.0001 --n_epochs 75 --lr_milestone 50 --batch_size 200 --weight_decay 0.5e-6 --pretrain False --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/mnist-run-test1/No-Min-Gradient-Operation/k-1/model.tar --ae_lr 0.0001 --ae_n_epochs 50 --ae_lr_milestone 50 --ae_batch_size 200 --ae_weight_decay 0.5e-3 --normal_class 3 --number_clusters 6;

### KMeans Experiments - No min operation for gradient ###
#python main.py cycif cycif_Net ../log/end-to-end-kmeans-models-no-min/multi-center-k-1 /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --number_clusters 1 --objective one-class --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/end-to-end-kmeans-models-no-scaling/multi-center-naive/model.tar --ae_lr 0.0001 --ae_n_epochs 100 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 5e-3;
#python main.py cycif cycif_Net ../log/end-to-end-kmeans-models-no-min/multi-center-k-2 /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --number_clusters 2 --objective one-class --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/end-to-end-kmeans-models-no-scaling/multi-center-naive/model.tar --ae_lr 0.0001 --ae_n_epochs 100 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 5e-3;

### KMeans Experiments - visualize UMAPs at each epoch ###
#python main.py mnist mnist_LeNet ../log/mnist-run-test1/No-Min-Gradient-Operation/Test /n/pfister_lab2/Lab/enovikov/shared/Data/MNIST --number_clusters 1 --objective one-class --lr 0.0001 --n_epochs 75 --lr_milestone 25 --batch_size 200 --weight_decay 0.5e-6 --pretrain True --ae_lr 0.0001 --ae_n_epochs 50 --ae_lr_milestone 25 --ae_batch_size 200 --ae_weight_decay 0.5e-3 --normal_class 3;
#python main.py mnist mnist_LeNet ../log/mnist-run-test1/No-Min-Gradient-Operation/Test /n/pfister_lab2/Lab/enovikov/shared/Data/MNIST --number_clusters 3 --objective one-class --lr 0.0001 --n_epochs 20 --lr_milestone 25 --batch_size 200 --weight_decay 0.5e-6 --pretrain False --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/mnist-run-test1/No-Min-Gradient-Operation/Exponential_LR_experiments/Exponential_LR_Decay_0.9_AE/model.tar --ae_lr 0.0001 --ae_n_epochs 50 --ae_lr_milestone 25 --ae_batch_size 200 --ae_weight_decay 0.5e-3 --normal_class 3;

#python main.py mnist mnist_LeNet ../log/mnist-run-test1/static-centers/k-2 /n/pfister_lab2/Lab/enovikov/shared/Data/MNIST --number_clusters 2 --objective one-class --lr 0.0001 --n_epochs 75 --lr_milestone 25 --batch_size 200 --weight_decay 0.5e-6 --pretrain False --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/mnist-run-test1/No-Min-Gradient-Operation/Exponential_LR_experiments/Exponential_LR_Decay_0.9_AE/model.tar --ae_lr 0.0001 --ae_n_epochs 50 --ae_lr_milestone 25 --ae_batch_size 200 --ae_weight_decay 0.5e-3 --normal_class 3;

### KMeans Experiments - init static centers ###
#python main.py cycif cycif_Net ../log/end-to-end-kmeans-static-centers/k-2 /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --number_clusters 2 --objective one-class --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/end-to-end-kmeans-models-no-scaling/multi-center-naive/model.tar --ae_lr 0.0001 --ae_n_epochs 100 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 5e-3;
#python main.py cycif cycif_Net ../log/end-to-end-kmeans-static-centers/k-3 /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --number_clusters 3 --objective one-class --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/end-to-end-kmeans-models-no-scaling/multi-center-naive/model.tar --ae_lr 0.0001 --ae_n_epochs 100 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 5e-3;
#python main.py cycif cycif_Net ../log/end-to-end-kmeans-static-centers/k-4 /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --number_clusters 4 --objective one-class --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/end-to-end-kmeans-models-no-scaling/multi-center-naive/model.tar --ae_lr 0.0001 --ae_n_epochs 100 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 5e-3;
#python main.py cycif cycif_Net ../log/end-to-end-kmeans-static-centers/k-6 /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --number_clusters 6 --objective one-class --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/end-to-end-kmeans-models-no-scaling/multi-center-naive/model.tar --ae_lr 0.0001 --ae_n_epochs 100 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 5e-3;

### KMeans Experiments - init static centers new pretrained AE ###
#python main.py cycif cycif_Net ../log/end-to-end-kmeans-static-centers-patience-25/k-1 /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --number_clusters 1 --objective one-class --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain True --ae_lr 0.0001 --ae_n_epochs 100 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 5e-3;
#python main.py cycif cycif_Net ../log/end-to-end-kmeans-static-centers-patience-25/k-15 /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --number_clusters 15 --objective one-class --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/end-to-end-kmeans-static-centers-patience-25/k-1/model.tar --ae_lr 0.0001 --ae_n_epochs 100 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 5e-3;
#python main.py cycif cycif_Net ../log/end-to-end-kmeans-static-centers-patience-25/k-10 /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --number_clusters 10 --objective one-class --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/end-to-end-kmeans-static-centers-patience-25/k-1/model.tar --ae_lr 0.0001 --ae_n_epochs 100 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 5e-3;
#python main.py cycif cycif_Net ../log/end-to-end-kmeans-static-centers-patience-25/k-5 /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --number_clusters 5 --objective one-class --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/end-to-end-kmeans-static-centers-patience-25/k-1/model.tar --ae_lr 0.0001 --ae_n_epochs 100 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 5e-3;
#python main.py cycif cycif_Net ../log/end-to-end-kmeans-static-centers-patience-25/k-20 /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --number_clusters 20 --objective one-class --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/end-to-end-kmeans-static-centers-patience-25/k-1/model.tar --ae_lr 0.0001 --ae_n_epochs 100 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 5e-3;
#python main.py cycif cycif_Net ../log/end-to-end-kmeans-static-centers-patience-25/k-25 /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --number_clusters 25 --objective one-class --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/end-to-end-kmeans-static-centers-patience-25/k-1/model.tar --ae_lr 0.0001 --ae_n_epochs 100 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 5e-3;
#python main.py cycif cycif_Net ../log/end-to-end-kmeans-static-centers-patience-25/k-30 /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --number_clusters 30 --objective one-class --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/end-to-end-kmeans-static-centers-patience-25/k-1/model.tar --ae_lr 0.0001 --ae_n_epochs 100 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 5e-3;

### KMeans with ResNet50 backbone - ResNet has global pooling layer, all ResNet layers frozen ###
#python main.py cycif cycif_ResNet ../log/cycif-run-test1 /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --number_clusters 1 --objective one-class --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain True --ae_lr 0.0001 --ae_n_epochs 100 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 5e-3;
#python main.py cycif cycif_ResNet ../log/resnet-end-to-end-kmeans-static-centers-patience-25/k-1 /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --number_clusters 1 --objective one-class --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain True --ae_lr 0.0001 --ae_n_epochs 250 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 5e-3;
#python main.py cycif cycif_ResNet ../log/resnet-end-to-end-kmeans-static-centers-patience-25/k-5 /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --number_clusters 5 --objective one-class --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/resnet-end-to-end-kmeans-static-centers-patience-25/k-1/model.tar --ae_lr 0.0001 --ae_n_epochs 250 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 5e-3;
#python main.py cycif cycif_ResNet ../log/resnet-with-global-pool-grad_False-end-to-end-kmeans-static-centers-patience-25/exps-wth-k-1-pretrained-AE/"$1"/"k-$2" /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --number_clusters "$2" --objective one-class --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/resnet-with-global-pool-grad_False-end-to-end-kmeans-static-centers-patience-25/k-1/model.tar --ae_lr 0.0001 --ae_n_epochs 250 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 5e-3;

## --> patience = 5 ##
#python main.py cycif cycif_ResNet ../log/resnet-end-to-end-kmeans-static-centers-patience-25/patience-5/k-5 /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --number_clusters 5 --objective one-class --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/resnet-end-to-end-kmeans-static-centers-patience-25/k-1/model.tar --ae_lr 0.0001 --ae_n_epochs 250 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 5e-3;
#python main.py cycif cycif_ResNet ../log/resnet-end-to-end-kmeans-static-centers-patience-25/patience-5/k-2 /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --number_clusters 2 --objective one-class --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/resnet-end-to-end-kmeans-static-centers-patience-25/k-1/model.tar --ae_lr 0.0001 --ae_n_epochs 250 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 5e-3;

# OFFICIAL EXPERIMENTS #
### KMeans with ResNet50 backbone (for transfer learning) - patience = 10, static centers ### 
## make new shell script - pass run, k- folder, and num_clusters arg (1) do for k-1 runs and then for (2) k>1 runs
#python main.py cycif cycif_ResNet ../log/resnet-static-centers-patience-10/"$1"/"k-$2" /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --number_clusters "$2" --objective one-class --lr 0.0001 --n_epochs 300 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain True --ae_lr 0.0001 --ae_n_epochs 150 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 5e-3;
#python main.py cycif cycif_ResNet ../log/resnet-static-centers-patience-10/"$1"/"k-$2" /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --number_clusters "$2" --objective one-class --lr 0.0001 --n_epochs 300 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/resnet-static-centers-patience-10/run2/k-1/model.tar --ae_lr 0.0001 --ae_n_epochs 150 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 5e-3;

### KMeans with ResNet50 backbone (for transfer learning) - patience = 20, static centers ### 
#python main.py cycif cycif_ResNet ../log/resnet-static-centers-patience-20/"$1"/"k-$2" /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --number_clusters "$2" --objective one-class --lr 0.0001 --n_epochs 300 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain True --ae_lr 0.0001 --ae_n_epochs 150 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 5e-3;
#python main.py cycif cycif_ResNet ../log/resnet-static-centers-patience-20/"$1"/"k-$2" /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --number_clusters "$2" --objective one-class --lr 0.0001 --n_epochs 300 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/resnet-static-centers-patience-20/ /model.tar --ae_lr 0.0001 --ae_n_epochs 150 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 5e-3;

### KMeans with ResNet50 backbone (for transfer learning) - patience = 25, static centers, only pretraining ResNet AE frozen ###
#python main.py cycif cycif_ResNet ../log/resnet-static-center-patience-25-pretrain_AE_grad_False/"$1"/"k-$2" /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --number_clusters "$2" --objective one-class --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain True --ae_lr 0.0001 --ae_n_epochs 150 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 0.5e-6;
#python main.py cycif cycif_ResNet ../log/resnet-static-center-patience-25-pretrain_AE_grad_False/"$1"/"k-$2" /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --number_clusters "$2" --objective one-class --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/resnet-static-center-patience-25-pretrain_AE_grad_False/run1/k-1/model.tar --ae_lr 0.0001 --ae_n_epochs 150 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 0.5e-6;

### Kmeans with ResNet50 backbone (for transfer learning) - patience = 25, static centers, Triplet Loss ###
#python main.py cycif cycif_ResNet ../log/resnet-static-centers-patience-25-Triplet-Loss/"$1"/"k-$2" /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --number_clusters "$2" --objective one-class --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain True --ae_lr 0.0001 --ae_n_epochs 150 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 0.5e-6;


### Kmeans with ResNet50 backbone (for transfer learning) - patience = 25, static centers, Deep SVDD Triplet Loss, Pretraining MSSIM Loss ###
#python main.py cycif cycif_ResNet ../log/resnet-static-centers-patience-25-Triplet-Loss-Pretraining-MSSIM-Loss/"$1"/"k-$2" /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --number_clusters "$2" --objective one-class --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain True --ae_lr 0.0001 --ae_n_epochs 50 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 0.5e-6;
python main.py cycif cycif_ResNet ../log/resnet-static-centers-patience-25-Triplet-Loss-Pretraining-MSSIM-Loss/"$1"/"k-$2" /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --number_clusters "$2" --objective one-class --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/resnet-static-centers-patience-25-Triplet-Loss-Pretraining-MSSIM-Loss/run3/k-1/model.tar --ae_lr 0.0001 --ae_n_epochs 50 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 0.5e-6;
## --- Scores are L2 --- ## 
#python main.py cycif cycif_ResNet ../log/resnet-static-patience-25-Triplet-MSSIM-all-L2-scores/"$1"/"k-$2" /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --number_clusters "$2" --objective one-class --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain True --ae_lr 0.0001 --ae_n_epochs 50 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 0.5e-6;


### Antibody aggreate data only Experiments ###
#python main.py cycif cycif_ResNet ../log/antibody-aggregates-experiments/resnet-static-centers-patience-25/"$1"/"k-$2" /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train_blobs/data/ --number_clusters "$2" --objective one-class --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain True --ae_lr 0.0001 --ae_n_epochs 150 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 0.5e-6;
#python main.py cycif cycif_ResNet ../log/antibody-aggregates-experiments/resnet-static-centers-patience-25-Triplet-Loss/"$1"/"k-$2" /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train_blobs/data/ --number_clusters "$2" --objective one-class --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain True --ae_lr 0.0001 --ae_n_epochs 150 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 0.5e-6;
#python main.py cycif cycif_ResNet ../log/antibody-aggregates-experiments/resnet-static-centers-patience-25-Triplet-Loss-Pretraining-MSSIM-Loss/"$1"/"k-$2" /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train_blobs/data/ --number_clusters "$2" --objective one-class --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain True --ae_lr 0.0001 --ae_n_epochs 50 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 0.5e-6;
## --- Scores are L2 --- ## 
#python main.py cycif cycif_ResNet ../log/resnet-static-patience-25-Triplet-MSSIM-all-L2-scores/blob-data/"$1"/"k-$2" /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train_blobs/data/ --number_clusters "$2" --objective one-class --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain True --ae_lr 0.0001 --ae_n_epochs 50 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 0.5e-6;


# Example Test Run:
#python main.py cycif cycif_Net ../log/cycif-run-test1 /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --load_config /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/cycif-run11-multi-center-k-2-full-kmeans/config.json --load_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/cycif-run11-multi-center-k-2-full-kmeans/model.tar --objective one-class --lr 0.0001 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False
#python visualize_anomalies.py cycif cycif_Net ../log/cycif-run-test1 /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --load_config /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/cycif-run4-no-bias-terms/config.json --load_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/cycif-run4-no-bias-terms/model.tar --objective one-class --number_clusters 1 --lr 0.0001 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False

# Example Train Run, Loading Pretrained AE:
#python main.py cycif cycif_Net ../log/cycif-run-test1 /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/cycif-run4-no-bias-terms/model.tar --objective one-class --lr 0.0001 --n_epochs 2 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False

# Debug, Loading Pretrained AE:
#python main.py cycif cycif_Net ../log/cycif-run-test1 /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/cycif-run4-no-bias-terms/model.tar --number_clusters 1 --objective one-class --lr 0.0001 --n_epochs 10 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False

### Kmeans Galleries ###
#python visualize_anomalies.py cycif cycif_Net ../log/cycif-run-test1 /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --objective one-class --number_clusters 1 --load_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/end-to-end-kmeans-models-no-scaling/multi-center-naive/model.tar --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False --ae_lr 0.0001 --ae_n_epochs 100 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 5e-3;
#python visualize_anomalies.py cycif cycif_Net ../log/cycif-run-test1 /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --objective one-class --number_clusters 2 --load_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/end-to-end-kmeans-models-no-scaling/multi-center-k-2/model.tar --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False --ae_lr 0.0001 --ae_n_epochs 100 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 5e-3;
#python visualize_anomalies.py cycif cycif_Net ../log/cycif-run-test1 /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --objective one-class --number_clusters 4 --load_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/end-to-end-kmeans-models-no-scaling/multi-center-k-4/model.tar --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False --ae_lr 0.0001 --ae_n_epochs 100 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 5e-3;


#TEST MNIST 
#python main.py mnist mnist_LeNet ../log/TEST /n/pfister_lab2/Lab/enovikov/shared/Data/MNIST --number_clusters 15 --objective one-class --lr 0.0001 --n_epochs 100 --lr_milestone 25 --batch_size 200 --weight_decay 0.5e-6 --pretrain False --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/mnist-run-test1/No-Min-Gradient-Operation/Exponential_LR_experiments/Exponential_LR_Decay_0.9_AE/model.tar --ae_lr 0.0001 --ae_n_epochs 50 --ae_lr_milestone 25 --ae_batch_size 200 --ae_weight_decay 0.5e-3 --normal_class 3;

# TEST ResNet
#python main.py cycif cycif_ResNet ../log/cycif-run-test1 /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --objective one-class --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain True --ae_lr 0.0001 --ae_n_epochs 5 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 5e-3;

# VIZ pretrained AE reconstruction
#python visualize_centers_TEST.py cycif cycif_ResNet ../log/cycif-run-test1 /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --objective one-class --number_clusters 1 --lr 0.0001 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/resnet-static-center-patience-25-pretrain_AE_grad_False/run2/k-1/model.tar --ae_lr 0.0001 --ae_n_epochs 150 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 0.5e-6;
#python visualize_centers_TEST.py cycif cycif_ResNet ../log/cycif-run-test1 /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --objective one-class --number_clusters 1 --lr 0.0001 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False --load_ae_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/resnet-static-centers-patience-20/run2/k-1/model.tar --ae_lr 0.0001 --ae_n_epochs 150 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 5e-3;

## TEST New Losses ## 
#python main.py cycif cycif_ResNet ../log/cycif-run-test1 /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --number_clusters 3 --objective one-class --lr 0.0001 --n_epochs 2 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain True --ae_lr 0.0001 --ae_n_epochs 2 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 0.5e-6;


#python visualize_anomalies.py cycif cycif_ResNet ../log/cycif-run-test1 /n/pfister_lab2/Lab/enovikov/data/Artifact-CyCIF-Data-2021/Sardana-Annotations/Edward/train/data/ --objective one-class --number_clusters 1 --load_model /n/pfister_lab2/Lab/enovikov/unsup-ano-detection/anomaly-project/Deep-SVDD-PyTorch/log/resnet-static-centers-patience-25-Triplet-Loss-Pretraining-MSSIM-Loss/run3/k-1/model.tar --lr 0.0001 --n_epochs 500 --lr_milestone 50 --batch_size 16 --weight_decay 0.5e-6 --pretrain False --ae_lr 0.0001 --ae_n_epochs 50 --ae_lr_milestone 50 --ae_batch_size 16 --ae_weight_decay 0.5e-6;


